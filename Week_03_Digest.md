# Week 03 学习指南 | STAT 140 实验设计

> **本周主题**：Neyman 推断方法与贝叶斯因果推断
> **学习目标**：掌握三大因果推断方法（Fisher、Neyman、Bayesian）的核心思想与应用

---

## 本周概览

欢迎来到 STAT 140 的第三周！这一周我们将补全因果推断的"黄金三角"。回想一下前两周的内容：

- **第一周**：我们学了势函数框架（Potential Outcomes Framework）和完全随机化设计（Completely Randomized Design, CRD），这是所有因果推断的基础
- **第二周**：我们学了 Fisher 的精确检验方法（Fisher's Exact Test），用来检验夏普零假设（Sharp Null Hypothesis）："这个处理对任何人都没有影响"

现在，**第三周**我们要学两个新的推断方法：

1. **Neyman 推断**（Module 5）：关注平均处理效应（Average Treatment Effect, ATE）的**估计**，而不是简单的假设检验
2. **贝叶斯因果推断**（Module 6）：将缺失的势函数视为随机变量，用贝叶斯方法更新我们对它们的信念

这三种方法从不同的哲学出发，但都基于随机化设计的力量。理解它们的异同，是成为因果推断专家的关键！

---

## 与前两周的联系

### 时间轴：三大方法如何产生

```
第一次世界大战后...
      ↓
  1920年代
      ↓
┌─────────────────┬──────────────────┬──────────────────┐
│                 │                  │                  │
Fisher            Neyman             (后来)
检验与区间估计     正式估计论         Rubin & 现代贝叶斯
1935年"统计方法与  1934年            1970年代+
科学推断"        "关于应用的问题"
│                 │                  │
"有没有效果？"    "平均效果多大？"   "效果分布是什么？"
(测试)            (估计)             (后验)
└─────────────────┴──────────────────┴──────────────────┘
```

### 三大方法的哲学对比

让我用一个简单的例子来说明这三种方法的不同：

**场景**：你做了一个药物试验，50人用药，50人用安慰剂。现在你想推断这个药有没有用。

| 问题 | Fisher | Neyman | Bayesian |
|------|--------|--------|----------|
| **核心问题** | 有没有任何效果？ | 平均效果是多少？ | 效果的完整分布是什么？ |
| **数学语言** | 检验 $\tau_i = 0$ 对所有 $i$ | 估计 $\tau = \frac{1}{N}\sum(\text{效果})$ | 更新 $p(\text{缺失数据}\|\text{观测数据})$ |
| **固定什么** | 固定观测结果，改变处理分配 | 固定观测结果，改变处理分配 | 固定处理分配和观测结果 |
| **灵活什么** | 处理效应是固定常数 | 处理效应可以是异质的 | 一切都有概率分布 |
| **何时最优** | 样本小，效应可能是齐次的 | 样本大，估计与CI都需要 | 可用强先验知识 |

---

## Module 5: Neyman 推断方法（Neymanian Inference）

### 这节课讲了什么？

Jerzy Neyman 在 1923-1934 年间发展了现代统计推断理论。他的核心观点是：

> "我们应该从**估计感兴趣的数量**（ATE）出发，而不是检验某个特定的假设。"

**与 Fisher 的根本区别**：

- **Fisher**：我有一个具体的假设（$H_0: \tau_i = 0$ 对所有 $i$），我想检验它是否为真。所以他用的是**假设检验范式**
- **Neyman**：我想知道处理的平均效果是多少，并给出一个置信区间。所以他用的是**估计与区间估计范式**

这个区别很深刻——它改变了统计学的整个风景。现代统计学的大部分（置信区间、p值、功效分析）都源自 Neyman 的思想。

### 核心概念

#### 1. Neyman vs Fisher：两种哲学对照

**Fisher 的世界观**（更像一个侦探）：
- 有一个犯人（零假设：夏普零假设，即处理对所有人都没有影响）
- 我看看证据（随机化排列分布）是否指向犯人
- 如果证据极端（p值很小），我拒绝零假设
- **关键**：零假设必须是很具体的（夏普的）

**Neyman 的世界观**（更像一个估计师）：
- 我不知道效果是什么，但我想估计它
- 每次做实验，由于随机化，我会得到稍微不同的估计
- 我想利用这种变异性来构造置信区间
- **关键**：我不需要假设任何零假设，我只需要估计感兴趣的量

**用房价为例**：

Fisher 说："房子改装前后价格相同吗？"
Neyman 说："改装平均能增加多少房价？增加的幅度在什么范围内？"

#### 2. 有限总体的平均处理效应（Finite-Population ATE）

在 Neyman 框架中，我们要估计的量是：

$$\tau = \frac{1}{N} \sum_{i=1}^{N} [Y_i(1) - Y_i(0)]$$

其中：
- $N$ 是总的样本量（我们关心的整个有限总体）
- $Y_i(1)$ 是单位 $i$ 在处理下的潜在结果
- $Y_i(0)$ 是单位 $i$ 在控制下的潜在结果
- $\tau$ 是所有单位平均效果

这跟 Fisher 用的是同一个 $\tau$，但我们现在要**估计**它，而不是**检验**它是否为零！

#### 3. 差值均值估计量（Difference-in-Means Estimator）

Neyman 提出的估计器很简单：

$$\hat{\tau} = \overline{Y}_t^{\text{obs}} - \overline{Y}_c^{\text{obs}}$$

其中：
- $\overline{Y}_t^{\text{obs}} = \frac{1}{N_t} \sum_{i: W_i=1} Y_i^{\text{obs}}$ 是处理组的平均观测结果
- $\overline{Y}_c^{\text{obs}} = \frac{1}{N_c} \sum_{i: W_i=0} Y_i^{\text{obs}}$ 是控制组的平均观测结果
- $N_t$ 和 $N_c$ 分别是两组的样本量

**简言之**：就是比较两组的平均值。但魔力在于分析它的性质！

#### 4. 无偏性证明（Why the Estimator is Unbiased）

**关键定理**：在完全随机化设计下，差值均值估计量是无偏的：

$$\mathbb{E}[\hat{\tau}] = \tau$$

**直观证明**：

考虑随机化的视角。对于任何处理分配方案 $\mathbf{W}$：

$$\hat{\tau}(\mathbf{W}) = \frac{1}{N_t(\mathbf{W})} \sum_{i: W_i=1} Y_i(1) - \frac{1}{N_c(\mathbf{W})} \sum_{i: W_i=0} Y_i(0)$$

现在对所有可能的处理分配取期望。由于是完全随机化的：
- 每个单位被分配到处理组的概率是 $\frac{N_t}{N}$
- 每个单位被分配到控制组的概率是 $\frac{N_c}{N}$

因此：

$$\mathbb{E}[\overline{Y}_t^{\text{obs}}] = \mathbb{E}\left[\frac{1}{N_t} \sum_{i: W_i=1} Y_i(1)\right] = \overline{Y}(1) = \frac{1}{N}\sum_{i=1}^N Y_i(1)$$

类似地：

$$\mathbb{E}[\overline{Y}_c^{\text{obs}}] = \overline{Y}(0) = \frac{1}{N}\sum_{i=1}^N Y_i(0)$$

所以：

$$\mathbb{E}[\hat{\tau}] = \overline{Y}(1) - \overline{Y}(0) = \frac{1}{N}\sum_{i=1}^{N}[Y_i(1) - Y_i(0)] = \tau \quad \checkmark$$

这个证明依赖于**随机化**——这就是为什么随机实验如此强大！

#### 5. 估计量的方差（Variance of the Estimator）

现在我们知道平均来说估计量会"击中"真实值。但它会有多少变异性？

在完全随机化设计下，Neyman 推导出：

$$\text{Var}(\hat{\tau}) = \frac{S^2(1)}{N_t} + \frac{S^2(0)}{N_c} - \frac{S^2(\tau)}{N}$$

其中：
- $S^2(1) = \frac{1}{N-1}\sum_{i=1}^N [Y_i(1) - \overline{Y}(1)]^2$ 是处理下潜在结果的方差
- $S^2(0) = \frac{1}{N-1}\sum_{i=1}^N [Y_i(0) - \overline{Y}(0)]^2$ 是控制下潜在结果的方差
- $S^2(\tau) = \frac{1}{N-1}\sum_{i=1}^N [\tau_i - \tau]^2$ 是个体处理效应的方差

**关键观察**：最后一项 $\frac{S^2(\tau)}{N}$ 总是非负的！

这意味着什么？这意味着：

$$\text{Var}(\hat{\tau}) \leq \frac{S^2(1)}{N_t} + \frac{S^2(0)}{N_c}$$

**直观理解**：
- 如果处理效应对每个人都是相同的（$S^2(\tau) = 0$，齐次效应），那么上面是等式
- 如果处理效应变化（$S^2(\tau) > 0$，异质效应），那么真实方差会更小！

这很神奇：**处理效应的异质性实际上降低了差值均值估计量的方差**！

**为什么？** 直观地说，如果每个人都会受益同等程度，那么随机分配的小差异就会导致大的估计错误。但如果有人受益多，有人受益少，那么随机分配的效应会相互抵消。

#### 6. 问题：$S^2(\tau)$ 是不可观测的

这里有个大问题：我们永远无法观测到 $S^2(\tau)$！

为什么？因为对每个单位，我们最多只能观测到 $Y_i(1)$ 或 $Y_i(0)$ 中的一个。我们不能同时看到一个人在处理和控制下的结果，所以无法计算 $\tau_i = Y_i(1) - Y_i(0)$。

这意味着我们不能直接计算真实的方差！

#### 7. 保守方差估计量（Conservative Variance Estimator）

Neyman 的聪明解决方案：既然 $\frac{S^2(\tau)}{N} \geq 0$，我们就使用**上界**作为方差的估计：

$$\hat{V}_{\text{Neyman}} = \frac{s_t^2}{N_t} + \frac{s_c^2}{N_c}$$

其中：
- $s_t^2 = \frac{1}{N_t-1}\sum_{i: W_i=1}[Y_i^{\text{obs}} - \overline{Y}_t^{\text{obs}}]^2$ 是处理组的样本方差
- $s_c^2 = \frac{1}{N_c-1}\sum_{i: W_i=0}[Y_i^{\text{obs}} - \overline{Y}_c^{\text{obs}}]^2$ 是控制组的样本方差

这个估计量有一个重要性质：

$$\mathbb{E}[\hat{V}_{\text{Neyman}}] = \frac{S^2(1)}{N_t} + \frac{S^2(0)}{N_c} \geq \text{Var}(\hat{\tau})$$

**所以这个估计是保守的**（overestimate）。这很好，因为：
- 过度估计方差意味着更宽的置信区间
- 这给了我们更多的保守性（保护性）

#### 8. 什么时候 Neyman 的估计完全准确？

当处理效应是齐次的时（$\tau_i = \tau$ 对所有 $i$），我们有 $S^2(\tau) = 0$，因此：

$$\text{Var}(\hat{\tau}) = \frac{S^2(1)}{N_t} + \frac{S^2(0)}{N_c}$$

在这种情况下，保守估计变成准确估计。所以 Neyman 的方法在齐次效应假设下是最精确的。

#### 9. Neyman 置信区间（Neyman's Confidence Interval）

基于以上，Neyman 的置信区间是：

$$95\% \text{ CI}: \hat{\tau} \pm 1.96 \times \sqrt{\hat{V}_{\text{Neyman}}}$$

这个区间基于两个关键假设：
1. **中心极限定理**（Central Limit Theorem）：当 $N$ 足够大时，$\hat{\tau}$ 近似服从正态分布
2. **保守方差估计**：我们使用样本方差作为总体方差的估计

**与 Fisher 置信区间的对比**：

| 特征 | Fisher | Neyman |
|------|--------|--------|
| 构造方法 | 通过假设检验反演 | 直接用 $\hat{\tau} \pm 1.96\,\text{SE}$ |
| 是否精确 | 是的，对任何 $N$ | 不是，依赖 CLT 和大样本 |
| 处理效应 | 必须假设齐次 | 可以是异质的 |
| 数据要求 | 小样本也可以 | 需要较大样本 |
| 方差估计 | 从测试分布精确推导 | 从样本方差保守估计 |

### 公式总结

**关键统计量汇总**：

1. **估计量**：$\hat{\tau} = \overline{Y}_t^{\text{obs}} - \overline{Y}_c^{\text{obs}}$

2. **方差（真实）**：$\text{Var}(\hat{\tau}) = \frac{S^2(1)}{N_t} + \frac{S^2(0)}{N_c} - \frac{S^2(\tau)}{N}$

3. **保守方差估计**：$\hat{V}_{\text{Neyman}} = \frac{s_t^2}{N_t} + \frac{s_c^2}{N_c}$

4. **标准误**：$\text{SE} = \sqrt{\hat{V}_{\text{Neyman}}}$

5. **95% 置信区间**：$[\hat{\tau} - 1.96 \times \text{SE}, \hat{\tau} + 1.96 \times \text{SE}]$

### 实例演练（Worked Example）

**背景**：一个咖啡因实验。研究咖啡因对认知表现的影响。

- 总样本：100 名大学生
- 处理组（有咖啡因）：50 人
- 控制组（无咖啡因）：50 人
- 结果变量：15 分钟的数学测试分数（0-100）

**观测数据**：

| 组别 | 样本量 | 平均分 | 样本方差 |
|------|--------|--------|---------|
| 咖啡因组 | 50 | 72.5 | 64.2 |
| 无咖啡因组 | 50 | 68.3 | 71.8 |

**计算步骤**：

**第1步**：计算差值均值估计量
$$\hat{\tau} = 72.5 - 68.3 = 4.2 \text{ 分}$$

解释：平均来说，咖啡因增加了 4.2 分的测试成绩。

**第2步**：计算保守方差估计
$$\hat{V}_{\text{Neyman}} = \frac{s_t^2}{N_t} + \frac{s_c^2}{N_c} = \frac{64.2}{50} + \frac{71.8}{50} = 1.284 + 1.436 = 2.720$$

**第3步**：计算标准误
$$\text{SE} = \sqrt{2.720} = 1.649$$

**第4步**：构造 95% 置信区间
$$95\% \text{ CI} = 4.2 \pm 1.96 \times 1.649 = 4.2 \pm 3.232 = (0.968, 7.432)$$

**解释**：我们有 95% 的信心认为，咖啡因的真实平均效应在 0.968 到 7.432 分之间。

**第5步**：假设检验（bonus）
由于 95% CI 不包含 0，我们可以说在 0.05 显著性水平下，咖啡因的效应是显著的。

---

## Module 6: 贝叶斯因果推断（Bayesian Causal Inference）

### 这节课讲了什么？

贝叶斯方法是因果推断的第三大支柱。与 Fisher 和 Neyman 的方法不同，贝叶斯方法的核心思想是：

> "将缺失的潜在结果视为**随机变量**，用贝叶斯定理将观测数据融入我们对它们的信念。"

**哲学对比**：

- **Fisher & Neyman**：给定的是哪些单位被处理（这是"固定的"），我们要从中学到什么
- **Bayesian**：给定的是观测结果和处理分配（这是"固定的"），我们用它们来更新关于缺失结果的信念

这是一个根本的视角转变。

### 核心概念

#### 1. 贝叶斯方法的核心思想

在科学表中（Science Table），对于处理过的单位，我们看到 $Y_i(1)$，但看不到 $Y_i(0)$。对于控制的单位，我们看到 $Y_i(0)$，但看不到 $Y_i(1)$。

**贝叶斯的想法**：

1. 我们不知道缺失的值，所以就把它们当作**随机变量**
2. 我们对这些随机变量的分布有一些先验信念（prior）
3. 我们观测到一些数据
4. 我们用贝叶斯定理更新我们的信念
5. 我们得到关于缺失值的**后验分布**（posterior distribution）

**贝叶斯定理**（回顾）：

$$p(\text{缺失} \mid \text{观测}) = \frac{p(\text{观测} \mid \text{缺失}) \times p(\text{缺失})}{p(\text{观测})}$$

在因果推断中：
- 缺失 = 没有看到的潜在结果
- 观测 = 看到的势函数值和处理分配

#### 2. 模型化潜在结果（Modeling Potential Outcomes）

要用贝叶斯方法，我们需要为潜在结果指定一个**生成模型**。

**简单例子**：正态模型

假设单位 $i$ 的两个潜在结果来自正态分布：

$$Y_i(1) \sim N(\mu_1, \sigma_1^2), \quad Y_i(0) \sim N(\mu_0, \sigma_0^2)$$

这里我们假设每个单位的潜在结果独立地来自相同的分布（这被称为**可交换性假设**）。

**贝叶斯模型的三层**：

```
第3层（先验）：μ₁, μ₀, σ₁², σ₀² 的分布
                    ↓
第2层（似然）：给定参数，观测结果的分布
                    ↓
第1层（数据）：观测到的处理和结果
```

#### 3. 单次填补 vs 多次填补（Single vs Multiple Imputation）

**错误的方法：单次填补（Naive Single Imputation）**

一个天真的想法：

1. 从控制组的观测值计算 $\mu_0$ 和 $\sigma_0^2$ 的点估计
2. 从处理组的观测值计算 $\mu_1$ 和 $\sigma_1^2$ 的点估计
3. 使用这些估计值填补缺失的潜在结果（例如，用 $\hat{\mu}_1$ 填补所有控制单位的 $Y_i(1)$）
4. 计算完成科学表的 ATE

**为什么这很糟糕？**

因为这**大大低估了不确定性**！当你填补缺失值时，你是在假设这些值被完美观测，但实际上它们不确定得很。这会导致过于紧的置信区间。

**正确的方法：多次填补（Multiple Imputation）**

更好的想法：

1. 从参数的**后验分布**中抽样（不是点估计）
2. 给定参数，从缺失值的**后验预测分布**中抽样
3. 完成科学表并计算 ATE
4. **重复多次**（比如 1000 次）
5. ATE 的后验分布就是这 1000 个估计值的经验分布

这样我们就正确地反映了不确定性！

#### 4. 多次填补的详细步骤（Step-by-Step）

假设我们有：
- 处理组：$Y_1^{\text{obs}}, \ldots, Y_{N_t}^{\text{obs}}$（观测到的 $Y_i(1)$ 值）
- 控制组：$Y_1^{\text{obs}}, \ldots, Y_{N_c}^{\text{obs}}$（观测到的 $Y_i(0)$ 值）

**算法**：

```
for m = 1 to M (M 通常是 1000 或更多):

  第1步：从后验中抽样参数
    从处理组数据推导 μ₁* 和 σ₁*² 的后验分布
    从控制组数据推导 μ₀* 和 σ₀*² 的后验分布
    从这些后验分布中各抽一组样本

  第2步：填补缺失值
    对于每个控制单位 i：
      从 N(μ₁*², σ₁*²) 中抽样得到 Ŷᵢ⁽¹⁾(m)
    对于每个处理单位 i：
      从 N(μ₀*², σ₀*²) 中抽样得到 Ŷᵢ⁽⁰⁾(m)

  第3步：计算完整数据的 ATE
    τ̂(m) = (1/N) Σᵢ [Ŷᵢ⁽¹⁾(m) - Ŷᵢ⁽⁰⁾(m)]

end for

返回：τ̂(1), τ̂(2), ..., τ̂(M)
```

这个 $M$ 个值的分布就是 $\tau$ 的**后验分布**。

#### 5. 贝叶斯自助法（Bayesian Bootstrap）

一个非参数版本由 Rubin 提出，不需要假设正态分布。

**核心想法**：

对于缺失的潜在结果，我们不假设任何具体的参数形式，而是直接从观测值的**经验分布**中重新抽样。

**算法**：

```
for m = 1 to M:

  第1步：从经验分布中重新抽样
    对于每个控制单位 i：
      从处理组的观测结果 {Y_j(1) : W_j = 1} 中有放回抽样
      得到 Ŷᵢ⁽¹⁾(m)

    对于每个处理单位 i：
      从控制组的观测结果 {Y_j(0) : W_j = 0} 中有放回抽样
      得到 Ŷᵢ⁽⁰⁾(m)

  第2步：计算该次填补的 ATE
    τ̂(m) = (1/N) Σᵢ [Ŷᵢ⁽¹⁾(m) - Ŷᵢ⁽⁰⁾(m)]

end for
```

**优点**：
- 完全非参数，不需要假设正态性
- 计算简单，可解释性强
- 自动处理小样本情况

#### 6. 实例演练（Worked Example）

回到咖啡因实验。这次我们用贝叶斯方法。

**原始数据**（和 Neyman 例子一样）：

| 组别 | 样本量 | 平均分 | 样本方差 |
|------|--------|--------|---------|
| 咖啡因组 | 50 | 72.5 | 64.2 |
| 无咖啡因组 | 50 | 68.3 | 71.8 |

**简化版贝叶斯分析**：

假设 $\mu_1 \sim N(72.5, 1.28)$，$\mu_0 \sim N(68.3, 1.44)$（从数据推导的近似后验）。

**第1次填补**（从正态后验中抽样）：

- 抽样得 $\mu_1^{(1)} = 72.8$，$\mu_0^{(1)} = 68.1$
- 对于 50 个控制单位，每个从 $N(72.8, 64.2)$ 中抽样一个 $Y_i(1)$
  比如得到：72.1, 74.3, 70.9, ...（50 个值）
- 对于 50 个处理单位，每个从 $N(68.1, 71.8)$ 中抽样一个 $Y_i(0)$
  比如得到：68.5, 66.2, 69.8, ...（50 个值）
- 现在我们有了完整的科学表！
- 计算 ATE：$\tau^{(1)} = \frac{1}{100}\sum_{i=1}^{100}[Y_i(1) - Y_i(0)]$
- 假设得到 $\tau^{(1)} = 4.5$

**第2次填补**（重复以上，但新的参数抽样）：

- 抽样得 $\mu_1^{(2)} = 72.2$，$\mu_0^{(2)} = 68.6$
- 重复填补和计算
- 假设得到 $\tau^{(2)} = 3.8$

...（重复 1000 次）

**后验分布**：

现在我们有 $\tau^{(1)}, \tau^{(2)}, \ldots, \tau^{(1000)}$。例如：
- 平均值（后验均值）：4.1
- 标准差（后验标准差）：1.6
- 95% 可信区间（Credible Interval）：[0.9, 7.3]（取2.5%和97.5%分位数）

**与 Neyman CI 的对比**：

- Neyman 95% CI：[0.97, 7.43]
- Bayesian 95% CrI：[0.9, 7.3]

两者非常相似！这种相似性在大样本时是普遍的。但在小样本或有强先验知识时，它们会有更大的差异。

### 贝叶斯方法的优缺点

**优点**：

1. **自然的不确定性处理**：不确定性体现在完整的后验分布中，不仅仅是点估计和 CI

2. **灵活性**：可以轻松处理复杂的设计和模型

3. **先验知识**：可以整合领域专家的先验知识

4. **任何估计量**：可以计算任何相关量的后验（ATT、CATE 等），而不仅仅是 ATE

5. **决策理论**：如果有损失函数，可以选择最优决策

**缺点**：

1. **模型依赖**：结果对模型假设很敏感（例如，假设正态性）

2. **先验敏感性**：特别是在小样本时，后验很大程度上取决于先验

3. **计算复杂**：通常需要 MCMC 或其他复杂算法

4. **解释困难**：后验不是频率意义上的"概率"，对很多人来说很反直觉

5. **假设透明度**：所有假设都必须明确，这有时候显得教条

---

## 三大推断方法完整对比

现在让我们综合地看一下 Fisher、Neyman 和 Bayesian 三种方法。

### 哲学与范式对比

| 维度 | Fisher | Neyman | Bayesian |
|------|--------|--------|----------|
| **时代** | 1920-1930年代 | 1920-1930年代 | 1970年代+ |
| **核心问题** | 有没有效果？ | 效果多大？ | 效果的完整分布？ |
| **推断形式** | 假设检验 | 点估计 + CI | 后验分布 |
| **固定对象** | 观测结果 | 观测结果 | 观测结果 + 处理分配 |
| **变化对象** | 处理分配 | 处理分配 | 缺失的潜在结果 |

### 技术细节对比

| 技术特征 | Fisher | Neyman | Bayesian |
|----------|--------|--------|----------|
| **样本量要求** | 任意大小都行 | 需要足够大（CLT） | 灵活，可用先验补偿小样本 |
| **处理效应** | 假设齐次 | 可以异质 | 可以异质 |
| **关键假设** | 夏普零假设 + CRD | CRD + CLT | 模型假设 + 先验 |
| **置信/可信区间** | 精确（对任何N） | 近似（大样本） | 精确（后验分位数） |
| **缺失数据处理** | 通过夏普零假设隐含填补 | 不需要处理 | 显式多次填补 |
| **计算** | 枚举所有排列 | 公式计算 | MCMC 或自助法 |

### 实践指南：什么时候用哪个方法？

**用 Fisher 当：**
- 样本很小（<30）
- 你的主要目标是检验存在效应，而不是量化大小
- 你有理由相信效应可能是齐次的
- 你需要精确推断，不能依赖大样本近似

**用 Neyman 当：**
- 样本中等或较大（>50）
- 你想估计平均效应和置信区间
- 效应可能异质，但你主要关心平均值
- 你想要标准的、容易解释的频率论推断
- 你没有强的先验知识可以利用

**用 Bayesian 当：**
- 你有关于潜在结果分布的强先验信息
- 样本很小，需要利用先验来弥补信息不足
- 你需要不仅仅是 ATE，还需要异质效应的后验分布
- 你的最终目标是决策，而不仅仅是推断
- 你的模型很复杂，难以用频率论方法处理

### 一个整合的例子

想象一个医学试验，100 名患者，50 人用新药，50 人用安慰剂。结果是血压降低（mm Hg）。

**Fisher 的问题**："有没有证据表明新药有效？"
- 建立夏普零假设：新药对每个患者都无效（$\tau_i = 0$）
- 计算在这个零假设下，观测到的差异有多极端
- 得到 p值 = 0.032，拒绝零假设
- **结论**：有证据表明新药有效

**Neyman 的问题**："新药平均能降低多少血压？"
- 估计 ATE：$\hat{\tau} = 12.3$ mm Hg
- 95% CI：[8.1, 16.5] mm Hg
- **结论**：我们估计新药平均降低血压约 12.3 mm Hg，真实值有 95% 的概率在 8.1 到 16.5 之间

**Bayesian 的问题**："鉴于我们之前对类似药物的了解，这个药的效果分布是什么？"
- 使用先验：基于过去 50 种类似药物的数据，我们相信新药的效应大约 $N(10, 3)$
- 结合当前数据
- 得到后验：$\tau \sim N(11.8, 1.9)$
- 95% 可信区间：[7.9, 15.7] mm Hg
- **结论**：综合考虑先验知识和当前数据，新药的效果有 95% 的可能性在 7.9 到 15.7 mm Hg 之间

这三个结论都是对的，但它们回答不同的问题，基于不同的哲学！

---

## 概念关系图

```
随机化实验的科学表
         ↓
    不完整的观测
    （缺失一半的潜在结果）
    /        |        \
   /         |         \
Fisher     Neyman    Bayesian
检验夏普      估计ATE    完整后验
零假设        + CI       分布
  |           |         |
排列检验    样本统计    模型推断
  |           |         |
假设          假设      假设
齐次效应      CLT      模型形式
  |           |         |
精确推断    近似推断    灵活推断
(小样本可用) (需要大样本) (需要先验)
```

---

## 本周关键术语表

### 英汉对照与定义

| 术语（英文） | 中文 | 定义 | 出现模块 |
|-------------|------|------|---------|
| Neymanian Inference | Neyman 推断 | 基于随机化和大样本理论的因果推断方法，强调 ATE 的估计和置信区间构造 | Module 5 |
| Difference-in-Means Estimator | 差值均值估计量 | $\hat{\tau} = \overline{Y}_t - \overline{Y}_c$，通过比较处理组和控制组的平均结果来估计 ATE | Module 5 |
| Average Treatment Effect (ATE) | 平均处理效应 | 处理效应在总体中的平均值，$\tau = \frac{1}{N}\sum_i [Y_i(1)-Y_i(0)]$ | Module 5 |
| Finite-Population | 有限总体 | 关注特定的、固定的 N 个单位的总体，而不是无穷假设总体 | Module 5 |
| Unbiasedness | 无偏性 | 估计量的期望等于被估计量，$\mathbb{E}[\hat{\tau}] = \tau$ | Module 5 |
| Conservative Variance Estimator | 保守方差估计 | 倾向于过度估计真实方差的估计，$\mathbb{E}[\hat{V}] \geq \text{Var}(\hat{\tau})$ | Module 5 |
| Homogeneous Treatment Effect | 齐次处理效应 | 处理效应对所有单位相同，$\tau_i = \tau$ for all $i$ | Module 5 |
| Heterogeneous Treatment Effect | 异质处理效应 | 处理效应在单位间变化，$\text{Var}(S^2(\tau)) > 0$ | Module 5, 6 |
| Central Limit Theorem (CLT) | 中心极限定理 | 样本均值的分布随 N 增大而趋向于正态分布 | Module 5 |
| Confidence Interval (CI) | 置信区间 | 频率论意义上的区间估计，长期来说包含真值的概率为 95% | Module 5 |
| Bayesian Causal Inference | 贝叶斯因果推断 | 将缺失的潜在结果视为随机变量，通过贝叶斯定理推断 | Module 6 |
| Multiple Imputation | 多次填补 | 通过多次从后验分布中抽样来处理缺失数据，保持不确定性 | Module 6 |
| Single Imputation | 单次填补 | 用点估计填补缺失值的方法，会低估不确定性（不推荐） | Module 6 |
| Posterior Distribution | 后验分布 | 给定观测数据后，关于参数或缺失值的条件分布 | Module 6 |
| Prior Distribution | 先验分布 | 在看到数据前，关于参数的信念分布 | Module 6 |
| Bayesian Bootstrap | 贝叶斯自助法 | 非参数的多次填补方法，从经验分布中重新抽样 | Module 6 |
| Credible Interval (CrI) | 可信区间 | 贝叶斯意义上的区间估计，真值在该区间的后验概率为 95% | Module 6 |
| Model-Based Inference | 模型化推断 | 基于指定的参数模型进行推断 | Module 6 |
| Predictive Distribution | 预测分布 | 给定观测数据和参数，关于未观测量的条件分布 | Module 6 |
| Exchangeability | 可交换性 | 假设观测值来自相同分布，顺序无关紧要 | Module 6 |

---

## 总结与预展

### 本周的三大收获

1. **Neyman 推断让我们能够估计和区间估计**：从 Fisher 的假设检验范式，我们扩展到了 Neyman 的估计范式。现在我们不仅可以说"有效果"，还可以说"有多大的效果"，并给出相应的置信区间。

2. **保守估计的巧妙性**：Neyman 的一个关键洞察是，虽然我们不能直接观测处理效应的方差 $S^2(\tau)$，但我们可以使用一个保守的上界，这在样本方差的帮助下变得可行。

3. **贝叶斯方法提供了完整的概率框架**：当我们准备放弃"样本空间的频率论"而接受"参数空间的概率论"时，贝叶斯方法提供了处理缺失数据和整合先验知识的优雅方案。

### 在课程中的位置

```
Week 1: 基础框架（势函数、CRD）
    ↓
Week 2: Fisher 的精确检验方法
    ↓
Week 3: Neyman 和 Bayesian 方法 ← 你在这里
    ↓
Week 4+: 分层、匹配、倾向性评分等高级设计
```

这三周构成了因果推断的哲学基础。无论后续学什么，这些概念都会不断出现。

### 下周预期

下周我们将深入**分层设计**（Stratified Design）和**匹配方法**（Matching），这些都是改进随机对照试验效率的方法。届时我们会看到，Neyman 和 Bayesian 的思想如何自然地扩展到这些设计。

---

## 学习建议

### 深入理解的三个关键点

1. **为什么 $S^2(\tau)/N$ 项存在？**
   花时间理解这一项为什么会出现，为什么它总是非负的，以及为什么异质效应实际上会降低估计的方差。这展示了因果推断的深刻含义。

2. **Neyman 和 Fisher 何时一致？**
   当样本足够大和处理效应齐次时，Neyman 的方法会趋向于 Fisher 的方法。理解这个极限关系会加深你对两种方法的理解。

3. **多次填补为什么必要？**
   亲手做一个简单的模拟，比较单次填补和多次填补的不确定性。这会让你深刻理解为什么正确处理不确定性很重要。

### 推荐练习

1. **重做两个例子（咖啡因实验）**，但改变样本量、方差等参数，看看结果如何变化

2. **自己设计一个简单实验**（比如关于学习方法的效果），用三种方法分析，比较结果

3. **用 R 或 Python 实现多次填补**，看看理论是如何转化为代码的

---

## 参考资源

### 理论基础
- Neyman, J. (1934). "On the two different aspects of the representative method." *Journal of the Royal Statistical Society*, 97, 558-625.
- Rubin, D. B. (1978). "Bayesian inference for causal effects in randomized experiments with noncompliance." *Journal of Educational and Behavioral Statistics*, 1, 444-457.

### 现代教材与讲义
- Imbens, G. W., & Wooldridge, J. M. (2009). "Recent developments in the econometrics of program evaluation." *Journal of Economic Literature*, 47, 5-86.
- Angrist, J. D., & Pischke, J.-S. (2008). *Mostly Harmless Econometrics*. Princeton University Press.

---

**祝你学习愉快！如有任何概念不清，建议重复阅读相关部分或向助教提问。**

