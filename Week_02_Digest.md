# Week 02 学习指南 | STAT 140 实验设计

## 本周概览

欢迎来到第二周！上周我们学习了**potential outcomes（潜在结果）** 框架和 **randomized controlled design（随机对照设计）**——这些是做因果推断的理论基础。现在，第二周将教我们如何使用这些工具进行**统计推断（inference）**，即从样本数据推断因果效应。

本周介绍的是三种经典推断方法中的第一种：**Fisher's Inference（Fisher 推断）**。Fisher 的方法是一种精确的、基于随机化的推断方法，特别适合小样本和精确推断的场景。

**核心问题**：我们观察到了处理组和对照组的结果，但这种差异是由处理引起的，还是仅仅因为随机变异？Fisher 的检验可以帮我们回答这个问题。

---

## 与上周的联系

### 回顾 Week 1 的关键概念

**Potential Outcomes（潜在结果）框架**：
- 每个单位 $i$ 都有两个潜在结果：$Y_i(1)$ (如果被处理) 和 $Y_i(0)$ (如果不被处理)
- 平均处理效应：$\text{ATE} = \frac{1}{N}\sum_{i=1}^{N}[Y_i(1) - Y_i(0)]$
- 但在任何实验中，我们只能观察到每个单位的**一个**潜在结果

**随机对照设计（Completely Randomized Design, CRD）**：
- 我们随机分配哪些单位接受处理（$W_i = 1$）和哪些不接受（$W_i = 0$）
- 这种随机化使得处理分配独立于潜在结果，保证了因果推断的有效性

### Week 2 的位置

有了这些基础后，我们可以提出关键问题：

> **观察到的处理效应是真实的因果效应，还仅仅是随机误差？**

这就是 **Fisher 推断** 要解决的问题。它提供了一种精确的、基于随机化机制本身的方法来进行假设检验。

---

## Module 3: Fisher 的精确零假设检验

### 这节课讲了什么？

这个模块引入了**Fisher's Randomization Test（Fisher随机化检验）**，这是一种独特的假设检验方法。与传统统计学中基于概率分布假设的检验不同，Fisher 的方法依赖于**我们对实验设计的了解**——特别是随机化分配机制。

Fisher 检验的核心思想非常简洁：
1. 假设处理对所有单位都没有效应
2. 在这个假设下，数据是固定的，**只有处理分配可能变化**
3. 我们枚举所有可能的处理分配，看在这些分配下，会有多少种情况产生我们观察到的（或更极端的）检验统计量
4. 比例就是 p 值

### 核心概念

#### 1. 精确零假设 (Sharp Null Hypothesis)

**定义**：
$$H_0: Y_i(1) = Y_i(0) \text{ 对所有单位 } i = 1, 2, \ldots, N$$

这个假设说的是：**处理对每一个单位都没有任何效应**。这就是为什么叫"sharp"（精确）——它不是说平均效应为零，而是说每个单位的效应都正好是零。

**为什么叫"精确"？**

想象我们有 6 个单位，我们观察到的实际结果是：
- 处理组（单位 1, 2, 3）：结果为 8, 9, 10
- 对照组（单位 4, 5, 6）：结果为 2, 3, 4

在 sharp null 假设下，我们知道：
- 单位 1 的潜在结果都是 8（无论被处理还是不被处理）
- 单位 2 的潜在结果都是 9
- ...等等

这意味着我们**完全知道**所有 12 个潜在结果中的每一个（6 个观察到的，6 个未观察到的）。这就是"精确"的含义——没有任何缺失信息。

**一个具体例子**：

假设你在测试一种学习方法。你随机选择 4 名学生，2 人用新方法（处理组），2 人用传统方法（对照组）。考试成绩如下：

| 学生 | 实际处理 | 实际成绩 |
|-----|-------|-------|
| A  | 新方法 | 85    |
| B  | 新方法 | 92    |
| C  | 传统方法 | 78    |
| D  | 传统方法 | 80    |

Sharp null 假设说：如果学生 A 用传统方法，成绩也会是 85；如果学生 C 用新方法，成绩还是 78。换句话说，**处理方法对任何学生的成绩都没有影响**。

#### 2. Fisher 随机化检验 (Fisher's Randomization Test)

**检验步骤**：

**第一步**：选择**检验统计量** $T$
最常用的是平均差：
$$T = \overline{Y}_t - \overline{Y}_c = \frac{1}{n_t}\sum_{i: W_i=1} Y_i^{\text{obs}} - \frac{1}{n_c}\sum_{i: W_i=0} Y_i^{\text{obs}}$$

其中 $Y_i^{\text{obs}}$ 是我们观察到的结果。

**第二步**：计算**观察到的检验统计量** $T^{\text{obs}}$

用实际数据计算。在上面的例子中：
$$T^{\text{obs}} = \frac{85 + 92}{2} - \frac{78 + 80}{2} = 88.5 - 79 = 9.5$$

**第三步**：在 sharp null 假设下，枚举**所有可能的处理分配**

这是关键步骤。在 sharp null 下，我们知道 4 名学生的结果固定为 {85, 92, 78, 80}，无论谁被分配到哪个处理组。我们需要问：在所有可能的处理分配中，有多少种会产生 $|T| \geq |T^{\text{obs}}| = 9.5$ 的检验统计量？

4 个单位中选 2 个被处理，有 $\binom{4}{2} = 6$ 种方式。让我们枚举：

| 处理组 | 对照组 | $T = \overline{Y}_t - \overline{Y}_c$ |
|------|------|-----|
| {A, B} | {C, D} | $(85+92)/2 - (78+80)/2 = 88.5 - 79 = 9.5$ ✓ |
| {A, C} | {B, D} | $(85+78)/2 - (92+80)/2 = 81.5 - 86 = -4.5$ |
| {A, D} | {B, C} | $(85+80)/2 - (92+78)/2 = 82.5 - 85 = -2.5$ |
| {B, C} | {A, D} | $(92+78)/2 - (85+80)/2 = 85 - 82.5 = 2.5$ |
| {B, D} | {A, C} | $(92+80)/2 - (85+78)/2 = 86 - 81.5 = 4.5$ |
| {C, D} | {A, B} | $(78+80)/2 - (85+92)/2 = 79 - 88.5 = -9.5$ ✓ |

**第四步**：计算 **p 值**

满足 $|T| \geq 9.5$ 的分配有 2 个（第 1 和第 6 行）。因此：
$$\text{p-value} = \frac{2}{6} = 0.333$$

**第五步**：做出决策

如果 p 值 < 0.05（或你选择的显著性水平），拒绝 sharp null。否则，无法拒绝。

在这个例子中，p = 0.333，我们**无法拒绝** sharp null。虽然观察到的差异是 9.5 分，但这在随机分配下是相当常见的（33% 的时间会发生），所以我们不能确定处理真的有效果。

#### 3. P 值的真实含义 (P-value)

**定义**：

p 值是**在零假设为真的条件下，观察到检验统计量至少与观察值一样极端的概率**。

**关键点——常见误解**：

❌ **错误理解 1**："p 值是零假设为真的概率"
- 错！p 值是在假设零假设**为真**的情况下的一个条件概率。它不告诉我们零假设本身是真还是假。

❌ **错误理解 2**："p < 0.05 意味着我的假设 100% 正确"
- 错！p < 0.05 只是说明观察到的结果在零假设下不太可能。这提供了反对零假设的证据，但不是绝对证明。

✓ **正确理解**：
p 值是一个**兼容性指标**。
- **小 p 值**（如 0.01）：观察到的结果在零假设下非常罕见。这提供了强证据反对零假设，支持另一个假设（处理有效果）。
- **大 p 值**（如 0.4）：观察到的结果在零假设下很常见。这意味着数据与零假设兼容，我们没有理由拒绝它。

**在 Fisher 框架中**，p 值有一个特别清晰的解释：

> 在所有可能的随机分配中，有多大比例会产生至少与我们观察到的结果一样极端的检验统计量？

这个解释不涉及任何贝叶斯概率或频率论的长期频率论证——它只是基于我们的设计中有多少种等可能的分配方式。

#### 4. 单侧 vs 双侧检验 (One-sided vs Two-sided)

**双侧检验** (Two-sided)：
$$\text{p-value} = \text{Pr}(|T| \geq |T^{\text{obs}}| \mid H_0)$$

我们关心的是**任何方向的极端**——处理效应太大（无论正还是负）。这是最常用的。

在学生学习方法的例子中，我们计算的是 $|T| \geq 9.5$，这是双侧的。

**单侧检验** (One-sided)：
$$\text{p-value} = \text{Pr}(T \geq T^{\text{obs}} \mid H_0)$$

我们只关心**一个方向**的极端。比如，如果我们事先知道新学习方法不会比传统方法差（只可能更好或无效），我们就可以进行单侧检验。

在学生例子中，单侧 p 值是 $\frac{1}{6} = 0.167$（因为只有第 1 行满足 $T \geq 9.5$）。

**什么时候用哪种？**
- **双侧**：当你对处理的方向没有预期时（推荐用这个）
- **单侧**：当你有强有力的理论或先验理由相信处理只能朝一个方向作用时

### 公式总结与例题

**关键公式**：

1. **检验统计量（平均差）**：
$$T = \overline{Y}_t - \overline{Y}_c$$

2. **p 值（双侧）**：
$$\text{p-value} = \frac{\#\{\text{分配 } w: |T(w)| \geq |T^{\text{obs}}|\}}{\text{总分配数}}$$

3. **在完全随机化设计中，总分配数**：
$$\binom{N}{n_t}$$

其中 $N$ 是总单位数，$n_t$ 是处理组大小。

**例题 1：最小可能 p 值**

假设你有 4 个单位，随机分配 2 个到处理组，2 个到对照组。由于总共只有 $\binom{4}{2} = 6$ 种分配，p 值只能是 $\frac{1}{6}, \frac{2}{6}, \frac{3}{6}, \frac{4}{6}, \frac{5}{6}, \frac{6}{6}$ 中的一个。**最小非零 p 值是 $\frac{1}{6} \approx 0.167$**，所以在样本量这么小的时候，无法达到 0.05 的显著性水平！

这说明 Fisher 检验不是"万能"的——样本越小，p 值的粒度越粗糙。

**例题 2：样本量增加时的情况**

如果你有 100 个单位，50 个处理，50 个对照，总分配数是 $\binom{100}{50} \approx 10^{29}$。现在 p 值可以非常精细，可以轻松达到 0.05 甚至 0.001。

---

## Module 4/4A: Fisher 置信区间

### 这节课讲了什么？

前面我们学会了如何进行假设检验：在 sharp null 假设下，能否拒绝处理对所有单位都无效？

现在我们反过来问：**可能的处理效应值有哪些？**

这就是**置信区间**的作用。我们将使用一个称为**test inversion（检验反转）** 的技巧，从假设检验推导出置信区间。

一个关键的假设是：**常数处理效应** (Constant Treatment Effect, CTE) 假设。也就是说，我们假设每个单位的处理效应都是相同的常数 $\tau$：

$$Y_i(1) - Y_i(0) = \tau \text{ 对所有 } i$$

这是一个比 sharp null 更灵活的假设，因为它允许处理有效果，但效果对所有单位都相同。

### 核心概念

#### 1. 常数处理效应假设 (Constant Treatment Effect)

**假设内容**：
$$Y_i(1) = Y_i(0) + \tau \text{ 对所有 } i = 1, 2, \ldots, N$$

其中 $\tau$ 是一个未知的常数。

**这意味着什么？**

如果 $\tau = 5$，那么处理使每个人的结果增加 5 分，无论这个人的基线是什么。

在学生学习方法的例子中，假设 $\tau = 3$。那么：
- 学生 A 实际上得了 85（用新方法），所以如果用传统方法会得 $85 - 3 = 82$
- 学生 C 实际上得了 78（用传统方法），所以如果用新方法会得 $78 + 3 = 81$

现在我们知道**所有 8 个潜在结果**了，即使我们没有直接观察到它们。

#### 2. 检验反转法 (Test Inversion)

**核心思想**：

对于每个**候选值** $\tau$，我们问：在常数处理效应为 $\tau$ 的假设下，我们的数据有多极端？

- 如果答案是"不太极端"（p 值大），$\tau$ 就与数据兼容。
- 如果答案是"非常极端"（p 值小），$\tau$ 就与数据不兼容。

**置信区间** = {所有与数据兼容的 $\tau$ 值}

**步骤**：

**第一步**：选择一个候选值 $\tau$（从某个范围开始，比如 $-100$ 到 $100$）

**第二步**：在常数处理效应 $\tau$ 的假设下，**补全潜在结果**

对于每个单位 $i$：
- 如果 $W_i = 1$（被处理）：$Y_i(0) = Y_i^{\text{obs}} - \tau$
- 如果 $W_i = 0$（对照）：$Y_i(1) = Y_i^{\text{obs}} + \tau$

**第三步**：进行 Fisher 随机化检验

用修正后的潜在结果，计算 p 值（就像 Module 3 那样）。

**第四步**：记录 p 值 $p(\tau)$

**第五步**：对许多不同的 $\tau$ 值重复步骤 1-4

**第六步**：构建置信区间

$$\text{95% CI} = \{\tau : p(\tau) > 0.05\}$$

即所有 p 值大于 0.05 的 $\tau$ 值。

**一个具体的例子**：

回到学生例子：

| 学生 | 处理 | 成绩 |
|-----|-----|-----|
| A  | 新 | 85  |
| B  | 新 | 92  |
| C  | 旧 | 78  |
| D  | 旧 | 80  |

测试 $\tau = 0$（sharp null）：
- 所有潜在结果：A: 85, B: 92, C: 78, D: 80
- Fisher 检验的 p 值（如我们之前计算的）= 0.333

测试 $\tau = 5$：
- A 的 $Y_A(0) = 85 - 5 = 80$
- B 的 $Y_B(0) = 92 - 5 = 87$
- C 的 $Y_C(1) = 78 + 5 = 83$
- D 的 $Y_D(1) = 80 + 5 = 85$
- 所以潜在结果是：A: 85, 80; B: 92, 87; C: 83, 78; D: 85, 80
- 对这个新数据进行 Fisher 检验，计算新的 p 值...

测试 $\tau = -10$：
- A 的 $Y_A(0) = 85 - (-10) = 95$
- B 的 $Y_B(0) = 92 - (-10) = 102$
- C 的 $Y_C(1) = 78 + (-10) = 68$
- D 的 $Y_D(1) = 80 + (-10) = 70$
- 进行 Fisher 检验，计算新的 p 值...

继续这个过程，对许多 $\tau$ 值，我们会得到一个 p 值的曲线。在某个范围内，p 值会大于 0.05，那就是我们的置信区间。

#### 3. Hodges-Lehmann 估计量 (Hodges-Lehmann Estimator)

**定义**：

Hodges-Lehmann (HL) 估计量是**最大化 p 值**的 $\tau$ 值——也就是与数据最兼容的处理效应。

数学上，它等于所有处理单位和对照单位之间**成对差异的中位数** (median):

$$\hat{\tau}_{\text{HL}} = \text{median}\{Y_i^{\text{obs}} - Y_j^{\text{obs}} : i \in \text{处理组}, j \in \text{对照组}\}$$

**为什么这样定义？**

考虑最简单的情况：1 个处理单位和 1 个对照单位。处理效应最自然的估计是什么？就是它们的差异！

当我们有多个处理单位和多个对照单位时，我们得到许多成对的差异。中位数是一个稳健的中心位置度量——它对异常值不敏感。

**例子**：

学生例子中：
- 处理单位：A (85), B (92)
- 对照单位：C (78), D (80)

所有成对差异：
- $85 - 78 = 7$
- $85 - 80 = 5$
- $92 - 78 = 14$
- $92 - 80 = 12$

排序：5, 7, 12, 14

中位数 = $(7 + 12) / 2 = 9.5$

所以 $\hat{\tau}_{\text{HL}} = 9.5$

有趣的是，这正好等于我们的观察到的平均处理效应！但这并非总是如此。

#### 4. Fisher 置信区间 vs 标准置信区间

**Fisher 置信区间**：
- 基于随机化分配机制
- 精确的（不需要大样本近似）
- 假设常数处理效应
- 计算可能很复杂（需要枚举许多 $\tau$ 值）
- 对小样本也有效

**标准置信区间**（如 $\overline{Y}_t \pm 1.96 \cdot SE$）：
- 基于中心极限定理（假设误差正态分布）
- 近似的（需要足够大的样本）
- 不需要假设常数处理效应
- 计算简单
- 对大样本效果好，小样本可能不准确

**什么时候用哪个？**
- 小样本 ($n < 30$)：Fisher 更可靠
- 大样本 ($n > 100$)：两者通常给出相似结果，标准方法更快
- 你想要精确推断：Fisher

### 公式总结与例题

**关键公式**：

1. **在假设 $\tau$ 下补全潜在结果**：
$$Y_i(1) = Y_i^{\text{obs}} + \tau \text{ 如果 } W_i = 0$$
$$Y_i(0) = Y_i^{\text{obs}} - \tau \text{ 如果 } W_i = 1$$

2. **Fisher 置信区间**：
$$\text{CI}_\alpha = \{\tau : p(\tau) > \alpha\}$$

其中 $\alpha$ 是显著性水平（如 0.05）。

3. **Hodges-Lehmann 点估计**：
$$\hat{\tau}_{\text{HL}} = \text{median}\{Y_i^{\text{obs}} - Y_j^{\text{obs}} : i \in T, j \in C\}$$

其中 $T$ 是处理组，$C$ 是对照组。

**例题 1：从单个成对差异到 HL 估计**

假设你有 3 个处理单位（成绩为 80, 85, 90）和 2 个对照单位（成绩为 70, 75）。

成对差异：
- $80 - 70 = 10$, $80 - 75 = 5$
- $85 - 70 = 15$, $85 - 75 = 10$
- $90 - 70 = 20$, $90 - 75 = 15$

所有差异：5, 10, 10, 15, 15, 20

中位数 = $(10 + 15) / 2 = 12.5$

所以 $\hat{\tau}_{\text{HL}} = 12.5$

**例题 2：置信区间的构建**

假设你对不同的 $\tau$ 值计算了 p 值：

| $\tau$ | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 |
|------|---|---|---|---|---|----|----|----|-----|
| $p(\tau)$ | 0.02 | 0.04 | 0.08 | 0.15 | 0.25 | 0.22 | 0.15 | 0.08 | 0.03 |

95% 置信区间是所有 $p(\tau) > 0.05$ 的 $\tau$。从表中看，这是 $\tau \in [6.5, 12.5]$（大约）。

注意 p 值曲线有一个**单峰**形状，这正是常数处理效应假设的典型特征。峰值 (0.25 at $\tau = 9$) 对应 Hodges-Lehmann 估计。

---

## Section 2 要点回顾：Fisherian 推断实践

Section 2 提供了对 Fisher 方法的实践应用。以下是关键的练习和技能：

### 1. 逐步进行 Fisher 随机化检验

**完整工作流程**：
1. 写出 sharp null 假设：$H_0: Y_i(1) = Y_i(0)$ 对所有 $i$
2. 选择检验统计量（通常是平均差）
3. 计算 $T^{\text{obs}}$
4. 在 CRD 分配下枚举所有 $\binom{N}{n_t}$ 种可能
5. 对每种分配计算 $T$
6. 统计满足 $|T| \geq |T^{\text{obs}}|$ 的分配数
7. p 值 = 满足条件的分配数 / 总分配数
8. 如果 p < 0.05，拒绝 null；否则无法拒绝

### 2. 理解完全随机化设计（CRD）的分配机制

CRD 中，所有 $\binom{N}{n_t}$ 种分配方式都是**等可能的**。这是 Fisher 检验中计算 p 值的基础。

如果你的设计不是 CRD（比如分层随机化），分配不再等可能，需要调整 p 值的计算方式。

### 3. 单侧 vs 双侧的实际应用

- 计算双侧 p 值：对 $|T| \geq |T^{\text{obs}}|$ 计数
- 计算单侧 p 值：对 $T \geq T^{\text{obs}}$ 计数（或 $\leq$，取决于你关心的方向）

通常坚持双侧，除非你有强理由相信处理只能朝一个方向作用。

### 4. 从检验到置信区间的反转

这是一个更高级的技能：
1. 选择一个 $\tau$ 范围（根据领域知识或初步估计）
2. 对范围内的许多 $\tau$ 值，补全潜在结果（给定 $\tau$）
3. 对每个 $\tau$ 进行 Fisher 检验
4. 记录 p 值 $p(\tau)$
5. 置信区间 = {$\tau$: $p(\tau) > 0.05$}

### 5. 计算 Hodges-Lehmann 估计

给定一个数据集：
1. 计算所有处理-对照配对的差异
2. 排序这些差异
3. 取中位数

如果有偶数个差异，中位数是中间两个的平均值。

### 6. 与 Week 1 概念的连接

**Potential Outcomes**：Fisher 方法的所有操作都基于潜在结果框架。Sharp null 说所有潜在结果都对应同一个数值。

**ATE (平均处理效应)**：如果 sharp null 为真，ATE = 0。Hodges-Lehmann 估计量是对 CTE 假设下共同处理效应的估计，可以看作是 ATE 的推广。

**随机化分配**：Fisher 检验的有效性完全依赖于 CRD 的随机化机制。正是因为分配是随机的，所有 $\binom{N}{n_t}$ 种分配才等可能，p 值的计算才有根据。

---

## 概念关系图

```
┌─────────────────────────────────────┐
│   Week 1: Potential Outcomes        │
│   & Randomized Design (CRD)         │
└────────────────┬────────────────────┘
                 │
                 ▼
    ┌────────────────────────────┐
    │  Week 2: Fisher Inference  │
    └────────────────────────────┘
           │                │
           ▼                ▼
    ┌──────────────┐  ┌────────────────┐
    │  Hypothesis  │  │  Confidence    │
    │  Testing     │  │  Intervals     │
    │  (Module 3)  │  │  (Module 4/4A) │
    └──────────────┘  └────────────────┘
           │                │
           ▼                ▼
    ├─Sharp Null    ├─Test Inversion
    │ H₀: τᵢ=0      │ H₀(τ): τᵢ=τ
    │ ∀i            │ ∀i (constant)
    │                │
    │ Randomization ├─Hodges-Lehmann
    │ Test          │ Estimator
    │ p-value       └────────────────┘
    └──────────────┘
           │
           ▼
    ┌─────────────────────────────┐
    │  Week 3: Neyman Inference   │
    │  (Sampling Uncertainty)     │
    └─────────────────────────────┘
```

---

## 本周关键术语表

| 中文术语 | 英文术语 | 定义/说明 |
|--------|--------|---------|
| **精确零假设** | Sharp Null Hypothesis | $H_0: Y_i(1) = Y_i(0) \forall i$; 处理对每个单位都无效果 |
| **随机化检验** | Randomization Test | 基于实际分配机制，枚举所有可能分配来计算 p 值 |
| **检验统计量** | Test Statistic | 用来衡量数据极端程度的函数，如平均差 |
| **P 值** | P-value | 在零假设下，观察到检验统计量至少与观察值一样极端的概率 |
| **显著性水平** | Significance Level | 拒绝零假设的阈值，通常为 0.05 |
| **单侧检验** | One-sided Test | 只在一个方向检验（T ≥ T_obs 或 T ≤ T_obs） |
| **双侧检验** | Two-sided Test | 两个方向都检验（\|T\| ≥ \|T_obs\|） |
| **常数处理效应** | Constant Treatment Effect (CTE) | $Y_i(1) - Y_i(0) = \tau \forall i$; 所有单位的处理效应相同 |
| **检验反转** | Test Inversion | 从假设检验导出置信区间的方法 |
| **置信区间** | Confidence Interval | 包含所有与数据兼容的参数值的区间 |
| **Hodges-Lehmann 估计量** | Hodges-Lehmann Estimator | 所有成对差异的中位数，常数处理效应的点估计 |
| **完全随机化设计** | Completely Randomized Design (CRD) | 将单位随机分配到处理和对照，各分配等可能 |

---

## 常见学习陷阱与澄清

### 陷阱 1：混淆"平均效应为零"和"精确零假设"

❌ 错误："Sharp null 是说平均处理效应为零"
✓ 正确："Sharp null 是说**每个单位**的处理效应都为零，即使是非常小的单位，处理都没有任何影响"

这两个不同！平均效应为零可以来自"一些单位受益，一些单位受害，相互抵消"。但 sharp null 说**没有任何单位从处理中受益**。

### 陷阱 2：认为 p > 0.05 意味着"接受零假设"

❌ 错误："p = 0.4 意味着零假设为真"
✓ 正确："p = 0.4 意味着如果零假设为真，观察到这样的数据并不罕见。我们没有强有力的证据反对零假设。"

"无法拒绝"不等于"接受"。可能是：
- 零假设真的为真
- 样本量太小，无法检测真实效应
- 数据的偶然性较大

### 陷阱 3：忘记常数处理效应是一个假设

Fisher 置信区间是基于 CTE 假设的。如果处理效应在单位间变化（异质处理效应），置信区间可能不准确。

### 陷阱 4：在大样本时过于依赖 Fisher 方法

对大样本（如 $n > 1000$），Fisher 随机化检验计算成本很高（需要枚举 $10^{300}$ 种分配！）。在这种情况下，可以：
- 使用标准统计方法（t 检验等）
- 用蒙特卡洛方法对随机分配采样，而不是全部枚举

---

## 学习建议

### 为了真正理解这周的内容，你应该：

1. **动手做例子**：找一个小数据集（$n \leq 6$），手工列举所有分配，计算 p 值。这会让你对 Fisher 的工作原理有深刻理解。

2. **对比两种方法**：对同一数据集，既算 Fisher 置信区间，也算标准置信区间（$\bar{Y}_t \pm 1.96 \cdot SE$）。看它们何时一致，何时不同。

3. **理解随机化的作用**：思考如果分配不是随机的（比如强壮的人被分配到处理组），Fisher 的方法为什么会失效。

4. **与 Week 1 连接**：每次看到一个 Fisher 方法，问自己："这用到了哪个 potential outcome 概念？"

5. **准备 Week 3**：Fisher 的方法很优雅，但有局限（样本小时 p 值粒度粗）。下周的 Neyman 方法会处理这个问题，着眼于**抽样变异** (sampling variation) 而不是**随机化分配**。

---

## 补充资源与推荐阅读

- **关键参考**：Rosenbaum (2002) "Observational Studies", Chapter 2
- **直观讲解**：想象所有可能的"平行世界"——每种随机分配对应一个平行世界。Fisher 检验问的是：在所有这些平行世界中，有多大比例会给出我们看到的极端结果？
- **计算工具**：对大样本，`library(permute)` 或 `library(coin)` 在 R 中实现了高效的随机化检验

---

**本周学习完成后，你应该能够：**

✓ 写出并解释 sharp null 假设
✓ 从头设计一个 Fisher 随机化检验
✓ 正确解释 p 值的含义
✓ 用检验反转法构建 Fisher 置信区间
✓ 计算 Hodges-Lehmann 点估计
✓ 比较 Fisher 方法和标准方法的优缺点
✓ 认识到 CTE 假设的重要性

祝学习愉快！
